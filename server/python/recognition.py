#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pythonæ‰‹æŒ‡æ¨¡æ€è¯†åˆ«è„šæœ¬
æ”¯æŒ4å¼ å›¾ç‰‡æ¯”å¯¹ï¼šæŒ‡çº¹ã€æŒ‡é™è„‰å¢å¼ºã€æŒ‡é™è„‰äºŒå€¼åŒ–ã€æŒ‡èŠ‚çº¹
"""

import argparse
import json
import sys
import os
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
from skimage import morphology
from torchvision import transforms
from transformers import ViTConfig, ViTModel


def mask_image2(image1: Image.Image, image2: Image.Image) -> Image.Image:
    """å›¾åƒæ©ç å¤„ç† - ä¿®å¤å°ºå¯¸ä¸åŒ¹é…é—®é¢˜"""
    # ç¡®ä¿ä¸¤å¼ å›¾ç‰‡å°ºå¯¸ä¸€è‡´
    target_size = image1.size  # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡çš„å°ºå¯¸
    if image2.size != target_size:
        image2 = image2.resize(target_size, Image.Resampling.LANCZOS)
    
    np_image1 = np.array(image1)
    np_image2 = np.array(image2)

    # ç¡®ä¿æ•°ç»„ç»´åº¦ä¸€è‡´
    if np_image1.shape != np_image2.shape:
        # å¦‚æœå½¢çŠ¶ä»ç„¶ä¸åŒ¹é…ï¼Œä½¿ç”¨æœ€å°çš„å…¬å…±å°ºå¯¸
        min_h = min(np_image1.shape[0], np_image2.shape[0])
        min_w = min(np_image1.shape[1], np_image2.shape[1])
        np_image1 = np_image1[:min_h, :min_w]
        np_image2 = np_image2[:min_h, :min_w]

    mask = np.all(np_image1 == [0, 0, 0], axis=-1).astype("uint8")
    selem = np.ones((5, 5))
    mask = morphology.binary_dilation(mask, selem)

    np_image2[mask] = [0, 0, 0]
    return Image.fromarray(np_image2)


class SiameseNetwork1(nn.Module):
    """ä¸‰æ¨¡æ€å­ªç”Ÿç½‘ç»œ"""
    def __init__(self, base_model1, base_model2, base_model3):
        super(SiameseNetwork1, self).__init__()

        self.base_model1 = base_model1

        self.fc1 = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 32),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(32, 2),
        )
        self.fc2 = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 32),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(32, 2),
        )
        self.fc3 = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 32),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(32, 2),
        )
        self.fc4 = nn.Sequential(
            nn.Linear(4, 2),
        )
        self.fc5 = nn.Sequential(
            nn.Linear(4, 2),
        )
        self.fc6 = nn.Sequential(
            nn.Linear(4, 2),
        )
        self.softmax = nn.Softmax(dim=1)

    def forward(self, img1, img2, img3, img4, img5, img6, img7, img8):
        feat1 = self.base_model1(img1).last_hidden_state[:, 0, :]
        feat2 = self.base_model1(img2).last_hidden_state[:, 0, :]

        feat3 = self.base_model1(img3).last_hidden_state[:, 0, :]
        feat4 = self.base_model1(img4).last_hidden_state[:, 0, :]
        feat32 = self.base_model1(img5).last_hidden_state[:, 0, :]
        feat42 = self.base_model1(img6).last_hidden_state[:, 0, :]

        feat5 = self.base_model1(img7).last_hidden_state[:, 0, :]
        feat6 = self.base_model1(img8).last_hidden_state[:, 0, :]

        x1 = feat1 - feat2
        x2 = feat3 - feat4
        x22 = feat32 - feat42
        x3 = feat5 - feat6

        x1 = self.fc1(x1)
        x1 = self.softmax(x1)

        x2 = self.fc2(x2)
        x2 = self.softmax(x2)

        x22 = self.fc2(x22)
        x22 = self.softmax(x22)

        x3 = self.fc3(x3)
        x3 = self.softmax(x3)

        x2 = torch.cat((x2, x22), dim=1)
        x2 = self.fc4(x2)
        x2 = self.softmax(x2)

        x23 = torch.cat((x2, x3), dim=1)
        x23 = self.fc5(x23)
        x23 = self.softmax(x23)

        x123 = torch.cat((x1, x23), dim=1)
        x123 = self.fc6(x123)
        x123 = self.softmax(x123)

        return x123


class FingerRecognition:
    """æ‰‹æŒ‡æ¨¡æ€è¯†åˆ«å™¨"""
    
    def __init__(self, model_path=None, device=None):
        if device is None:
            self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])
        
        # åˆå§‹åŒ–ViTæ¨¡å‹
        config = ViTConfig()
        vit1 = ViTModel(config)
        
        # åˆå§‹åŒ–ä¸‰æ¨¡æ€æ¨¡å‹
        self.model = SiameseNetwork1(base_model1=vit1, base_model2=None, base_model3=None)
        
        # é»˜è®¤ä½¿ç”¨å·²çŸ¥å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶
        if model_path is None:
            # å°è¯•ä½¿ç”¨é»˜è®¤çš„æ¨¡å‹è·¯å¾„ 
            default_model_path = r"C:\Users\28145\Desktop\py\model_epoch_3.pth"
            # å¤‡ç”¨è·¯å¾„ï¼šé¡¹ç›®ä¸­çš„æ¨¡å‹æ–‡ä»¶
            project_model_path = os.path.join(os.path.dirname(__file__), "..", "..", "models", "model_epoch_3.pth")
            
            if os.path.exists(default_model_path):
                model_path = default_model_path
                print(f"ğŸ“ ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„: {model_path}", file=sys.stderr)
            elif os.path.exists(project_model_path):
                model_path = project_model_path
                print(f"ğŸ“ ä½¿ç”¨é¡¹ç›®æ¨¡å‹è·¯å¾„: {model_path}", file=sys.stderr)
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶åœ¨è·¯å¾„: {default_model_path} æˆ– {project_model_path}", file=sys.stderr)
        
        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼Œå°è¯•åŠ è½½æƒé‡
        if model_path and os.path.exists(model_path):
            try:
                # ä½¿ç”¨å·²éªŒè¯å¯ç”¨çš„åŠ è½½æ–¹æ³•
                checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
                
                # æå–state_dict
                if isinstance(checkpoint, dict):
                    if 'model_state_dict' in checkpoint:
                        state_dict = checkpoint['model_state_dict']
                    elif 'state_dict' in checkpoint:
                        state_dict = checkpoint['state_dict']
                    elif 'model' in checkpoint:
                        state_dict = checkpoint['model']
                    else:
                        state_dict = checkpoint
                else:
                    state_dict = checkpoint
                
                # æ¸…ç†state_dictä¸­çš„module.å‰ç¼€
                cleaned_state_dict = {}
                for k, v in state_dict.items():
                    if k.startswith("module."):
                        cleaned_state_dict[k[7:]] = v
                    else:
                        cleaned_state_dict[k] = v
                
                # åŠ è½½æƒé‡
                missing_keys, unexpected_keys = self.model.load_state_dict(cleaned_state_dict, strict=False)
                
                if len(missing_keys) > 0:
                    print(f"è­¦å‘Šï¼šç¼ºå°‘çš„é”®: {missing_keys[:5]}...", file=sys.stderr)
                if len(unexpected_keys) > 0:
                    print(f"è­¦å‘Šï¼šå¤šä½™çš„é”®: {unexpected_keys[:5]}...", file=sys.stderr)
                    
                print(f"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ: {model_path}", file=sys.stderr)
                self.model_loaded = True
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºæƒé‡: {e}", file=sys.stderr)
                self.model_loaded = False
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨éšæœºæƒé‡", file=sys.stderr)
            self.model_loaded = False
        
        self.model.to(self.device)
        self.model.eval()
    
    def recognize(self, fp1_path, fp2_path, vein_aug1_path, vein_aug2_path, 
                  vein_bin1_path, vein_bin2_path, knuckle1_path, knuckle2_path):
        """
        è¿›è¡Œæ‰‹æŒ‡æ¨¡æ€è¯†åˆ«
        Args:
            fp1_path: æŒ‡çº¹å›¾ç‰‡1è·¯å¾„
            fp2_path: æŒ‡çº¹å›¾ç‰‡2è·¯å¾„
            vein_aug1_path: æŒ‡é™è„‰å¢å¼ºå›¾ç‰‡1è·¯å¾„
            vein_aug2_path: æŒ‡é™è„‰å¢å¼ºå›¾ç‰‡2è·¯å¾„
            vein_bin1_path: æŒ‡é™è„‰äºŒå€¼å›¾ç‰‡1è·¯å¾„
            vein_bin2_path: æŒ‡é™è„‰äºŒå€¼å›¾ç‰‡2è·¯å¾„
            knuckle1_path: æŒ‡èŠ‚çº¹å›¾ç‰‡1è·¯å¾„
            knuckle2_path: æŒ‡èŠ‚çº¹å›¾ç‰‡2è·¯å¾„
        """
        try:
            # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            files = [fp1_path, fp2_path, vein_aug1_path, vein_aug2_path,
                    vein_bin1_path, vein_bin2_path, knuckle1_path, knuckle2_path]
            
            for file_path in files:
                if not os.path.exists(file_path):
                    raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # åŠ è½½å›¾åƒ
            img1 = Image.open(fp1_path).convert('RGB')
            img2 = Image.open(fp2_path).convert('RGB')
            img2 = img2.resize((320, 240))
            img2 = mask_image2(img1, img2).convert('RGB')
            
            img3 = Image.open(vein_aug1_path).convert('RGB')
            img4 = Image.open(vein_aug2_path).convert('RGB')
            img5 = Image.open(vein_bin1_path).convert('RGB')
            img6 = Image.open(vein_bin2_path).convert('RGB')
            img7 = Image.open(knuckle1_path).convert('RGB')
            img8 = Image.open(knuckle2_path).convert('RGB')
            
            # é¢„å¤„ç†
            tensor1 = self.transform(img1).unsqueeze(0).to(self.device)
            tensor2 = self.transform(img2).unsqueeze(0).to(self.device)
            tensor3 = self.transform(img3).unsqueeze(0).to(self.device)
            tensor4 = self.transform(img4).unsqueeze(0).to(self.device)
            tensor5 = self.transform(img5).unsqueeze(0).to(self.device)
            tensor6 = self.transform(img6).unsqueeze(0).to(self.device)
            tensor7 = self.transform(img7).unsqueeze(0).to(self.device)
            tensor8 = self.transform(img8).unsqueeze(0).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(tensor1, tensor2, tensor3, tensor4, 
                                   tensor5, tensor6, tensor7, tensor8)
            
            # è·å–æ¦‚ç‡åˆ†æ•°
            prob_different = outputs[0, 0].item()
            prob_same = outputs[0, 1].item()
            
            # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ—¶ï¼Œè°ƒæ•´é˜ˆå€¼åˆ¤æ–­
            if self.model_loaded:
                # å¯¹äºè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨æ›´åˆç†çš„é˜ˆå€¼
                confidence_threshold = 0.6
                is_match = prob_same > confidence_threshold
                confidence = prob_same
            else:
                # å¯¹äºéšæœºæƒé‡ï¼Œä½¿ç”¨ç®€å•çš„æ¯”è¾ƒ
                is_match = prob_same > prob_different  
                confidence = max(prob_same, prob_different)
            
            return {
                'success': True,
                'is_match': is_match,
                'match_probability': prob_same,
                'different_probability': prob_different,
                'confidence': confidence,
                'model_loaded': self.model_loaded
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


def main():
    parser = argparse.ArgumentParser(description='æ‰‹æŒ‡æ¨¡æ€è¯†åˆ«è„šæœ¬')
    
    # è¾“å…¥å›¾ç‰‡å‚æ•°
    parser.add_argument('--fp1', required=True, help='æŒ‡çº¹å›¾ç‰‡1è·¯å¾„')
    parser.add_argument('--fp2', required=True, help='æŒ‡çº¹å›¾ç‰‡2è·¯å¾„')
    parser.add_argument('--vein-aug1', required=True, help='æŒ‡é™è„‰å¢å¼ºå›¾ç‰‡1è·¯å¾„')
    parser.add_argument('--vein-aug2', required=True, help='æŒ‡é™è„‰å¢å¼ºå›¾ç‰‡2è·¯å¾„')
    parser.add_argument('--vein-bin1', required=True, help='æŒ‡é™è„‰äºŒå€¼å›¾ç‰‡1è·¯å¾„')
    parser.add_argument('--vein-bin2', required=True, help='æŒ‡é™è„‰äºŒå€¼å›¾ç‰‡2è·¯å¾„')
    parser.add_argument('--knuckle1', required=True, help='æŒ‡èŠ‚çº¹å›¾ç‰‡1è·¯å¾„')
    parser.add_argument('--knuckle2', required=True, help='æŒ‡èŠ‚çº¹å›¾ç‰‡2è·¯å¾„')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--model-path', help='è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--device', default='auto', help='è®¡ç®—è®¾å¤‡ (cpu/cuda:0/auto)')
    parser.add_argument('--output-json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼ç»“æœ')
    
    args = parser.parse_args()
    
    # è®¾å¤‡é€‰æ‹©
    if args.device == 'auto':
        device = None
    else:
        device = args.device
    
    try:
        # åˆå§‹åŒ–è¯†åˆ«å™¨
        recognizer = FingerRecognition(model_path=args.model_path, device=device)
        
        # æ‰§è¡Œè¯†åˆ«
        result = recognizer.recognize(
            args.fp1, args.fp2,
            args.vein_aug1, args.vein_aug2,
            args.vein_bin1, args.vein_bin2,
            args.knuckle1, args.knuckle2
        )
        
        if args.output_json:
            print(json.dumps(result, ensure_ascii=False))
        else:
            if result['success']:
                print(f"è¯†åˆ«æˆåŠŸ:")
                print(f"  åŒ¹é…ç»“æœ: {'åŒ¹é…' if result['is_match'] else 'ä¸åŒ¹é…'}")
                print(f"  åŒ¹é…æ¦‚ç‡: {result['match_probability']:.4f}")
                print(f"  ä¸åŒ¹é…æ¦‚ç‡: {result['different_probability']:.4f}")
                print(f"  ç½®ä¿¡åº¦: {result['confidence']:.4f}")
            else:
                print(f"è¯†åˆ«å¤±è´¥: {result['error']}")
                sys.exit(1)
                
    except Exception as e:
        if args.output_json:
            print(json.dumps({'success': False, 'error': str(e)}, ensure_ascii=False))
        else:
            print(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
